"""
agents/learning_effectiveness_agent.py
í•™ìŠµ íš¨ê³¼ì„± ë¶„ì„ Agent
"""
from langchain_core.prompts import ChatPromptTemplate
from .base import AgentState, EVALUATION_CRITERIA, llm, extract_score, get_web_context


def learning_effectiveness_agent(state: AgentState) -> AgentState:
    """Agent 2: í•™ìŠµ íš¨ê³¼ì„± ë¶„ì„"""
    print("\nğŸ“š [Agent 2] í•™ìŠµ íš¨ê³¼ì„± ë¶„ì„ ì‹œì‘...")
    
    startup_name = state["startup_name"]
    checklist = EVALUATION_CRITERIA["learning_effectiveness"]
    context = get_web_context(startup_name, "í•™ìŠµ íš¨ê³¼ ì„±ê³¼")
    
    prompt = ChatPromptTemplate.from_template("""
êµìœ¡ ìŠ¤íƒ€íŠ¸ì—… '{startup_name}'ì˜ í•™ìŠµ íš¨ê³¼ì„±ì„ í‰ê°€í•˜ì„¸ìš”.

**í‰ê°€ ê¸°ì¤€ (ê° í•­ëª© 0-10ì ):**
{checklist}

**ì°¸ê³  ìë£Œ:**
{context}

**ì¶œë ¥ í˜•ì‹:**
ê° í•­ëª©ë³„ë¡œ:
- ì ìˆ˜ (0-10ì )
- ê·¼ê±° (URL í¬í•¨)

ë§ˆì§€ë§‰ì— **ì´ì : [0-100 ìˆ«ì]** í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
""")
    
    response = (prompt | llm).invoke({
        "startup_name": startup_name,
        "checklist": "\n".join(f"{i+1}. {q}" for i, q in enumerate(checklist)),
        "context": context
    })
    
    analysis = response.content
    score = extract_score(analysis)
    
    state["learning_effectiveness_score"] = score
    state["learning_effectiveness_analysis_evidence"] = analysis
    
    print(f"âœ… [Agent 2] ì™„ë£Œ - í•™ìŠµíš¨ê³¼ ì ìˆ˜: {score}")
    return state