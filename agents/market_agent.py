"""
agents/market_agent.py
ì‹œì¥ì„± ë¶„ì„ Agent (RAG í¬í•¨)
"""
import os
from langchain_core.prompts import ChatPromptTemplate
from langchain_community.document_loaders import PyMuPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma
try:
    from langchain_tavily import TavilySearch
except ImportError:
    from langchain_community.tools.tavily_search import TavilySearchResults as TavilySearch
from .base import AgentState, EVALUATION_CRITERIA, llm, extract_score


def market_agent(state: AgentState) -> AgentState:
    """Agent 3: ì‹œì¥ì„± ë¶„ì„ (RAG í¬í•¨)"""
    print("\nğŸ’° [Agent 3] ì‹œì¥ì„± ë¶„ì„ ì‹œì‘...")
    
    startup_name = state["startup_name"]
    checklist = EVALUATION_CRITERIA["market"]
    
    # PDF RAG
    pdf_path = os.getenv("PDF_PATH", "")
    rag_context = ""
    if pdf_path and os.path.exists(pdf_path):
        try:
            loader = PyMuPDFLoader(pdf_path)
            docs = loader.load_and_split(RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100))
            vectorstore = Chroma.from_documents(docs, OpenAIEmbeddings())
            retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
            retrieved = retriever.get_relevant_documents(f"{startup_name} êµìœ¡ ì‹œì¥")
            rag_context = "\n".join([doc.page_content for doc in retrieved])
        except:
            rag_context = "PDF ë¡œë”© ì‹¤íŒ¨"
    
    # Web Search
    try:
        search = TavilySearch(max_results=10)
        results = search.invoke(f"{startup_name} êµìœ¡ ì‹œì¥ ê·œëª¨")
        # TavilySearchëŠ” ë¬¸ìì—´ì„ ì§ì ‘ ë°˜í™˜í•˜ê±°ë‚˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•  ìˆ˜ ìˆìŒ
        if isinstance(results, str):
            web_context = results
        elif isinstance(results, list):
            web_context = "\n".join([f"- {r.get('title', r.get('content', str(r)))}" for r in results])
        else:
            web_context = str(results)
    except Exception as e:
        web_context = f"ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}"
    
    combined = f"[PDF ìë£Œ]\n{rag_context}\n\n[ì›¹ ê²€ìƒ‰]\n{web_context}"
    
    prompt = ChatPromptTemplate.from_template("""
êµìœ¡ ìŠ¤íƒ€íŠ¸ì—… '{startup_name}'ì˜ ì‹œì¥ì„±ì„ í‰ê°€í•˜ì„¸ìš”.

**í‰ê°€ ê¸°ì¤€ (ê° í•­ëª© 0-10ì ):**
{checklist}

**ì°¸ê³  ìë£Œ:**
{context}

**ì¶œë ¥ í˜•ì‹:**
ê° í•­ëª©ë³„ë¡œ:
- ì ìˆ˜ (0-10ì )
- ê·¼ê±° (URL í¬í•¨)

ë§ˆì§€ë§‰ì— **ì´ì : [0-100 ìˆ«ì]** í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
""")
    
    response = (prompt | llm).invoke({
        "startup_name": startup_name,
        "checklist": "\n".join(f"{i+1}. {q}" for i, q in enumerate(checklist)),
        "context": combined
    })
    
    analysis = response.content
    score = extract_score(analysis)
    
    print(f"âœ… [Agent 3] ì™„ë£Œ - ì‹œì¥ì„± ì ìˆ˜: {score}")
    
    # ìì‹ ì˜ í•„ë“œë§Œ ë°˜í™˜
    return {
        "market_score": score,
        "market_analysis_evidence": analysis
    }