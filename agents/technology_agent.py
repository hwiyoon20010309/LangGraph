"""
agents/technology_agent.py
ê¸°ìˆ ë ¥ ë¶„ì„ Agent
"""
from langchain_core.prompts import ChatPromptTemplate
from .base import AgentState, EVALUATION_CRITERIA, llm, extract_score, get_web_context


def technology_agent(state: AgentState) -> AgentState:
    """Agent 1: ê¸°ìˆ ë ¥ ë¶„ì„"""
    print("\nğŸ”§ [Agent 1] ê¸°ìˆ ë ¥ ë¶„ì„ ì‹œì‘...")
    
    startup_name = state["startup_name"]
    checklist = EVALUATION_CRITERIA["technology"]
    context = get_web_context(startup_name, "êµìœ¡ ê¸°ìˆ  í˜ì‹ ")
    
    prompt = ChatPromptTemplate.from_template("""
êµìœ¡ ìŠ¤íƒ€íŠ¸ì—… '{startup_name}'ì˜ ê¸°ìˆ ë ¥ì„ í‰ê°€í•˜ì„¸ìš”.

**í‰ê°€ ê¸°ì¤€ (ê° í•­ëª© 0-10ì ):**
{checklist}

**ì°¸ê³  ìë£Œ:**
{context}

**ì¶œë ¥ í˜•ì‹:**
ê° í•­ëª©ë³„ë¡œ:
- ì ìˆ˜ (0-10ì )
- ê·¼ê±° (URL í¬í•¨)

ë§ˆì§€ë§‰ì— **ì´ì : [0-100 ìˆ«ì]** í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
""")
    
    response = (prompt | llm).invoke({
        "startup_name": startup_name,
        "checklist": "\n".join(f"{i+1}. {q}" for i, q in enumerate(checklist)),
        "context": context
    })
    
    analysis = response.content
    score = extract_score(analysis)
    
    print(f"âœ… [Agent 1] ì™„ë£Œ - ê¸°ìˆ ë ¥ ì ìˆ˜: {score}")
    
    # ìì‹ ì˜ í•„ë“œë§Œ ë°˜í™˜
    return {
        "technology_score": score,
        "technology_analysis_evidence": analysis
    }