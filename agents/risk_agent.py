"""
agents/risk_agent.py
ë¦¬ìŠ¤í¬ ë¶„ì„ Agent
"""
from typing import Dict
from langchain_core.prompts import ChatPromptTemplate
from .base import AgentState, EVALUATION_CRITERIA, extract_score, get_web_context
from agents.llm_factory import get_llm  # âœ… llmì€ ê³µì¥ í•¨ìˆ˜ë¡œ ìƒì„±(ORG/PROJECT ëŒ€ì‘)

MAX_CONTEXT_CHARS = 9000  # âœ… ê³¼ë„í•œ í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ë°©ì§€

def _safe_extract_total_score(text: str, default: int = 60) -> int:
    """ì´ì (0-100)ì„ ì•ˆì „í•˜ê²Œ ì¶”ì¶œí•˜ê³  ë²”ìœ„ í´ë¨í”„."""
    try:
        score = extract_score(text)  # ì‚¬ìš©ìê°€ ë§Œë“  íŒŒì„œ
        if score is None:
            return default
        # 0~100 ë²”ìœ„ ë³´ì •
        score = int(score)
        if score < 0: score = 0
        if score > 100: score = 100
        return score
    except Exception:
        return default

def risk_agent(state: AgentState) -> Dict:
    """Agent 6: ë¦¬ìŠ¤í¬ ë¶„ì„"""
    print("\nâš ï¸ [Agent 6] ë¦¬ìŠ¤í¬ ë¶„ì„ ì‹œì‘...")

    startup_name = state["startup_name"]
    checklist = EVALUATION_CRITERIA["risk"]

    # âœ… ì›¹ ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘ + ê¸¸ì´ ì œí•œ
    raw_context = get_web_context(startup_name, "ë¦¬ìŠ¤í¬ ì´ìŠˆ ë¬¸ì œ") or ""
    context = raw_context[:MAX_CONTEXT_CHARS] if raw_context else "ê´€ë ¨ ê³µê°œ ìë£Œê°€ ì¶©ë¶„ì¹˜ ì•ŠìŠµë‹ˆë‹¤."

    # âœ… ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¡œ ì—­í•  ê³ ì • + ì¶œë ¥ ê·œê²© ê°•ì¡°
    prompt = ChatPromptTemplate.from_messages([
        ("system",
         "ë‹¹ì‹ ì€ VCì˜ ë¦¬ìŠ¤í¬ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ê·¼ê±° ê¸°ë°˜ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ê³ , "
         "ìš”ì²­ëœ ì¶œë ¥ í˜•ì‹ì„ ë°˜ë“œì‹œ ì§€í‚¤ì„¸ìš”. í•˜ì´ë£¨ë¨¸/ì¶”ì¸¡ì€ ê¸ˆì§€."),
        ("human", """
êµìœ¡ ìŠ¤íƒ€íŠ¸ì—… '{startup_name}'ì˜ ë¦¬ìŠ¤í¬ë¥¼ í‰ê°€í•˜ì„¸ìš”.

**í‰ê°€ ê¸°ì¤€ (ê° í•­ëª© 0-10ì , ì ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡ ë¦¬ìŠ¤í¬ê°€ ë‚®ìŒ):**
{checklist}

**ì°¸ê³  ìë£Œ:**
{context}

**ì¶œë ¥ í˜•ì‹(ë°˜ë“œì‹œ ì¤€ìˆ˜):**
ê° í•­ëª©ë³„ë¡œ:
- ì ìˆ˜ (0-10ì , ë†’ì„ìˆ˜ë¡ ë¦¬ìŠ¤í¬ ë‚®ìŒ)
- ê·¼ê±° (ê°€ëŠ¥í•˜ë©´ URL í¬í•¨)

ë§ˆì§€ë§‰ ì¤„ì— **ì´ì : [0-100 ìˆ«ì]** ë§Œ í•œ ì¤„ë¡œ í‘œê¸°í•˜ì„¸ìš”.
""")
    ])

    # âœ… ORG/PROJECT í—¤ë” í¬í•¨ëœ LLM ìƒì„± (401 ë°©ì§€)
    llm = get_llm(model="gpt-4o-mini", temperature=0.1)

    try:
        response = (prompt | llm).invoke({
            "startup_name": startup_name,
            "checklist": "\n".join(f"{i+1}. {q}" for i, q in enumerate(checklist)),
            "context": context
        })
        analysis = getattr(response, "content", str(response))
        score100 = _safe_extract_total_score(analysis)  # 0~100
        # ğŸ‘‰ ë©”ì¸ì—ì„œ 0~5/0~10 ìŠ¤ì¼€ì¼ì´ë©´ ì—¬ê¸°ì„œ ë³€í™˜í•´ë„ ë¨. ì˜ˆ: 100ì â†’5ì  í™˜ì‚°
        #    riskëŠ” "ë†’ì„ìˆ˜ë¡ ì•ˆì „"ì´ë¯€ë¡œ 100ì ì„ 5ì ìœ¼ë¡œ ìŠ¤ì¼€ì¼ ë‹¤ìš´:
        risk_score_10 = round(score100 / 10)  # 0~10
        print(f"âœ… [Agent 6] ì™„ë£Œ - ë¦¬ìŠ¤í¬ ì´ì (100ê¸°ì¤€): {score100} â†’ 10ì  ìŠ¤ì¼€ì¼: {risk_score_10}")
        return {
            "risk_score": risk_score_10,
            # í•„ìš”ì‹œ ì¦ê±° ì €ì¥:
            # "risk_analysis_evidence": analysis[:2000],
        }

    except Exception as e:
        # âœ… ì¸ì¦/ë„¤íŠ¸ì›Œí¬/íƒ€ì„ì•„ì›ƒ ë“± ì˜ˆì™¸ í´ë°±
        print(f"âŒ [Agent 6] í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        # ë³´ìˆ˜ì  ê¸°ë³¸ê°’(ì¤‘ê°„ì¹˜) ë°˜í™˜
        return {
            "risk_score": 3
        }
