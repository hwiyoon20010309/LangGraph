# -*- coding: utf-8 -*-
"""
EdTech íˆ¬ì íŒŒì´í”„ë¼ì¸ (A: ëª©ë¡ ìƒì„± -> ì „ì²´ í‰ê°€/ë­í‚¹ -> ìˆœìœ„ ê¸°ë°˜ B-H ê²€ì¦)

íë¦„:
1. Agent A: ì—¬ëŸ¬ ì¿¼ë¦¬ë¡œ Tavily ê²€ìƒ‰ -> ì´ë¦„ ì¶”ì¶œ -> AI í•„í„°ë§ -> ì´ˆê¸° ëª©ë¡ ìƒì„± (CSV ì €ì¥)
2. EvaluateAll & Rank: ì´ˆê¸° ëª©ë¡ì˜ ëª¨ë“  ìŠ¤íƒ€íŠ¸ì—… ìƒì„¸ ì •ë³´ ê²€ìƒ‰ -> 6ê¸°ì¤€ AI í‰ê°€ -> ì´ì  ê³„ì‚° -> ìˆœìœ„ ë§¤ê¸°ê¸° (CSV ì €ì¥ & State ì €ì¥)
3. Select Ranked Startup: ìˆœìœ„ ëª©ë¡ì—ì„œ ë‹¤ìŒ ìˆœì„œì˜ ìŠ¤íƒ€íŠ¸ì—… ì„ íƒ
4. Agents B-H: ì„ íƒëœ ìŠ¤íƒ€íŠ¸ì—… ìˆœì°¨ ê²€ì¦ (pass/fail)
5. ë¼ìš°íŒ…: fail ì‹œ ë‹¤ìŒ ìˆœìœ„ ì„ íƒ, ëª¨ë‘ pass ì‹œ ì„±ê³µ, ëª©ë¡ ì†Œì§„ ì‹œ ì¢…ë£Œ

í•„ìš”:
- pip install langgraph langchain langchain-openai langchain-community tiktoken requests beautifulsoup4 python-dotenv rich langchain-opentutorial pandas
- .env:
    OPENAI_API_KEY=sk-...
    TAVILY_API_KEY=tvly-...
"""

import os
import re
import requests
import pandas as pd
import random
import json
import time
from typing import List, Set, Dict, Optional, TypedDict, Literal
from dotenv import load_dotenv
from openai import OpenAI
from rich import print

# LangGraph / LangChain
from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_teddynote.tools.tavily import TavilySearch

# === â‘  í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ===
load_dotenv()
TAVILY_API_KEY = os.getenv("TAVILY_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not TAVILY_API_KEY:
    raise ValueError("ğŸš¨ Tavily API key missing (.env).")
if not OPENAI_API_KEY:
    raise ValueError("ğŸš¨ OpenAI API key missing (.env).")

client = OpenAI(api_key=OPENAI_API_KEY)
TAVILY_URL = "https://api.tavily.com/search"
# CSV íŒŒì¼ëª… ì •ì˜
INITIAL_STARTUP_CSV = "ai_filtered_startups.csv"
RANKED_CSV_FILE = "ranked_startup_evaluations.csv"

# === â‘¡-1. ìŠ¤íƒ€íŠ¸ì—… ëª©ë¡ ìƒì„±ì„ ìœ„í•œ ì„¤ì • ===
AGGREGATION_QUERIES = [
    "AI êµìœ¡ ìŠ¤íƒ€íŠ¸ì—… ëª©ë¡ (ì˜ˆ: Riiid, Mathpresso, Sana Labs, Squirrel AI ë“±)",
    "EdTech ë¶„ì•¼ì—ì„œ ì¸ê³µì§€ëŠ¥(AI)ì„ í™œìš©í•˜ëŠ” ì£¼ìš” ìŠ¤íƒ€íŠ¸ì—…",
    "Top AI education or EdTech startups 2025 funding news",
    "AI tutoring platform startups using adaptive learning investment",
]
NAME_PATTERN = re.compile(
    r"\b([A-Z][A-Za-z0-9&'\-]*(?:\s+[A-Z][A-Za-z0-9&'\-]*){0,2})\b"
)
STOPWORDS = {
    "AI", "Labs", "Learning", "Education", "EdTech", "Systems", "Company", "Group",
    "Technology", "Technologies", "Platform", "Startup", "News", "Report", "Top",
    "Software", "Tools", "Adaptive", "Artificial", "Intelligence", "Market",
    "Overview", "Trend", "Global", "Data", "Model", "Classroom", "Program", "School",
    "South", "Korea", "Best", "List", "World",
}

# === â‘¡-2. ìƒì„¸ í‰ê°€ë¥¼ ìœ„í•œ ê¸°ì¤€ ===
EVALUATION_CRITERIA = {
    "technology": [
        "ì œí’ˆì´ êµìœ¡ ë¬¸ì œë¥¼ ëª…í™•í•˜ê²Œ í•´ê²°í•˜ëŠ”ê°€?", "AI/ML ê¸°ìˆ  í™œìš©ë„ê°€ ë†’ì€ê°€?",
        "ê¸°ìˆ ì˜ í˜ì‹ ì„±ê³¼ ì°¨ë³„í™”ê°€ ìˆëŠ”ê°€?", "ê¸°ìˆ ì  êµ¬í˜„ ê°€ëŠ¥ì„±ì´ ë†’ì€ê°€?",
        "ì‹œìŠ¤í…œì˜ í™•ì¥ ê°€ëŠ¥ì„±ì´ ìˆëŠ”ê°€?", "ê¸°ìˆ  ì•ˆì •ì„±ê³¼ ë³´ì•ˆì´ í™•ë³´ë˜ì–´ ìˆëŠ”ê°€?",
        "ë°ì´í„° ê¸°ë°˜ í•™ìŠµ ìµœì í™”ê°€ ê°€ëŠ¥í•œê°€?", "API ì—°ë™ ë° í™•ì¥ì„±ì´ ë›°ì–´ë‚œê°€?",
        "ê¸°ìˆ  ë¬¸ì„œí™”ê°€ ì˜ ë˜ì–´ ìˆëŠ”ê°€?", "ì˜¤í”ˆì†ŒìŠ¤ í™œìš© ë° ì»¤ë®¤ë‹ˆí‹° ê¸°ì—¬ë„ê°€ ìˆëŠ”ê°€?"
    ],
    "learning_effectiveness": [
        "í•™ìŠµ ì„±ê³¼ ì¸¡ì • ì§€í‘œê°€ ëª…í™•í•œê°€?", "í•™ìŠµì ë§Œì¡±ë„ê°€ ë†’ì€ê°€?",
        "í•™ìŠµ ì™„ë£Œìœ¨ì´ ìš°ìˆ˜í•œê°€?", "í•™ìŠµ íš¨ê³¼ ê²€ì¦ ì‚¬ë¡€ê°€ ìˆëŠ”ê°€?",
        "ê°œì¸í™” í•™ìŠµ ì§€ì›ì´ ê°€ëŠ¥í•œê°€?", "í•™ìŠµ ë°ì´í„° ë¶„ì„ ë° í”¼ë“œë°± ì œê³µì´ ë˜ëŠ”ê°€?",
        "êµì‚¬/ê°•ì‚¬ ì§€ì› ë„êµ¬ê°€ ìˆëŠ”ê°€?", "í•™ìŠµì ì°¸ì—¬ë„ í–¥ìƒ ë°©ì•ˆì´ ìˆëŠ”ê°€?",
        "ì½˜í…ì¸  í’ˆì§ˆì´ ìš°ìˆ˜í•œê°€?", "í•™ìŠµ ê²½ë¡œ ì¶”ì²œì´ íš¨ê³¼ì ì¸ê°€?"
    ],
    "market": [
        "íƒ€ê²Ÿ êµìœ¡ ì‹œì¥ ê·œëª¨ê°€ í°ê°€?", "ì‹œì¥ ì„±ì¥ë¥ ì´ ë†’ì€ê°€?",
        "ìˆ˜ìµ ëª¨ë¸ì´ ëª…í™•í•˜ê³  ì‹¤í˜„ ê°€ëŠ¥í•œê°€?", "ê³ ê° ê¸°ë°˜(B2B/B2C)ì´ í™•ë³´ë˜ì–´ ìˆëŠ”ê°€?",
        "ê°€ê²© ì „ëµì´ í•©ë¦¬ì ì¸ê°€?", "ì‹œì¥ ì§„ì… ì „ëµì´ êµ¬ì²´ì ì¸ê°€?",
        "ê³ ê° íšë“ ë¹„ìš©(CAC)ì´ ì ì ˆí•œê°€?", "ìƒì•  ê°€ì¹˜(LTV)ê°€ ë†’ì€ê°€?",
        "íŒŒíŠ¸ë„ˆì‹­ í™•ë³´ ê°€ëŠ¥ì„±ì´ ìˆëŠ”ê°€?", "ê¸€ë¡œë²Œ ì‹œì¥ ì§„ì¶œ ê°€ëŠ¥ì„±ì´ ìˆëŠ”ê°€?"
    ],
    "competition": [
        "ê²½ìŸì‚¬ ëŒ€ë¹„ ëª…í™•í•œ ì°¨ë³„í™” ìš”ì†Œê°€ ìˆëŠ”ê°€?", "ì‹œì¥ ì§„ì… ì¥ë²½ì´ ì¡´ì¬í•˜ëŠ”ê°€?",
        "ê²½ìŸ ìš°ìœ„(íŠ¹í—ˆ, ê¸°ìˆ , ë„¤íŠ¸ì›Œí¬)ê°€ ìˆëŠ”ê°€?", "ë¸Œëœë“œ ì¸ì§€ë„ê°€ í˜•ì„±ë˜ì–´ ìˆëŠ”ê°€?",
        "ê³ ê° ì¶©ì„±ë„ê°€ ë†’ì€ê°€?", "ì„ ì  íš¨ê³¼(First Mover)ê°€ ìˆëŠ”ê°€?",
        "ë„¤íŠ¸ì›Œí¬ íš¨ê³¼ê°€ ì‘ë™í•˜ëŠ”ê°€?", "ì „í™˜ ë¹„ìš©(Switching Cost)ì´ ë†’ì€ê°€?",
        "ê²½ìŸì‚¬ ëŒ€ë¹„ ê°€ì„±ë¹„ê°€ ìš°ìˆ˜í•œê°€?", "ì§€ì† ê°€ëŠ¥í•œ ê²½ìŸë ¥ì´ ìˆëŠ”ê°€?"
    ],
    "growth_potential": [
        "ì‹œì¥ í™•ì¥ ê°€ëŠ¥ì„±ì´ í°ê°€?", "ì œí’ˆ ë‹¤ê°í™” ê³„íšì´ ìˆëŠ”ê°€?",
        "ê¸€ë¡œë²Œ ì§„ì¶œ ì „ëµì´ êµ¬ì²´ì ì¸ê°€?", "íŒŒíŠ¸ë„ˆì‹­ í™•ëŒ€ ê¸°íšŒê°€ ìˆëŠ”ê°€?",
        "ì¸ìˆ˜í•©ë³‘(M&A) ê°€ëŠ¥ì„±ì´ ìˆëŠ”ê°€?", "IPO ê°€ëŠ¥ì„±ì´ ìˆëŠ”ê°€?",
        "ìŠ¤ì¼€ì¼ì—…ì„ ìœ„í•œ ì¸í”„ë¼ê°€ ì¤€ë¹„ë˜ì–´ ìˆëŠ”ê°€?", "íˆ¬ì ìœ ì¹˜ ì´ë ¥ì´ ìˆëŠ”ê°€?",
        "ì„±ì¥ ë¡œë“œë§µì´ ëª…í™•í•œê°€?", "10ë°° ì„±ì¥(10x Growth) ê°€ëŠ¥ì„±ì´ ìˆëŠ”ê°€?"
    ],
    "risk": [
        "ì¬ë¬´ ë¦¬ìŠ¤í¬ê°€ ë‚®ì€ê°€?", "ë²•ì /ê·œì œ ë¦¬ìŠ¤í¬ê°€ ë‚®ì€ê°€?", "ê¸°ìˆ  ë¦¬ìŠ¤í¬ê°€ ë‚®ì€ê°€?",
        "ì‹œì¥ ë¦¬ìŠ¤í¬ê°€ ë‚®ì€ê°€?", "ê²½ì˜ì§„ ë¦¬ìŠ¤í¬ê°€ ë‚®ì€ê°€?", "ìš´ì˜ ë¦¬ìŠ¤í¬ê°€ ë‚®ì€ê°€?",
        "í‰íŒ ë¦¬ìŠ¤í¬ê°€ ë‚®ì€ê°€?", "ê²½ìŸ ë¦¬ìŠ¤í¬ê°€ ë‚®ì€ê°€?",
        "íŒŒíŠ¸ë„ˆì‹­ ì˜ì¡´ë„ ë¦¬ìŠ¤í¬ê°€ ë‚®ì€ê°€?", "í™•ì¥ì„± ë¦¬ìŠ¤í¬ê°€ ë‚®ì€ê°€?"
    ]
}

# === â‘¢ LangGraph ìƒíƒœ ìŠ¤í‚¤ë§ˆ ===
class AgentState(TypedDict, total=False):
    initial_candidates: List[str]
    ranked_evaluations: List[Dict]
    current_rank_index: int
    current_startup_details: Dict
    analysis_b: str
    analysis_c: str
    analysis_d: str
    analysis_e: str
    analysis_f: str
    analysis_g: str
    analysis_h: str
    last_decision: Literal["continue", "reject"]

# === â‘£ Helper í•¨ìˆ˜ë“¤ ===

def tavily_search_for_aggregation(query: str, max_results: int = 40) -> dict:
    """ìŠ¤íƒ€íŠ¸ì—… ëª©ë¡ ìƒì„±ì„ ìœ„í•œ Tavily ê²€ìƒ‰ í•¨ìˆ˜"""
    headers = {"Authorization": f"Bearer {TAVILY_API_KEY}", "Content-Type": "application/json"}
    payload = {
        "query": query, "max_results": min(max_results, 50),
        "include_answer": True, "search_depth": "advanced",
    }
    try:
        res = requests.post(TAVILY_URL, json=payload, headers=headers, timeout=30)
        res.raise_for_status()
        return res.json()
    except requests.exceptions.RequestException as e:
        print(f"âŒ (ëª©ë¡ ìƒì„±) Tavily ê²€ìƒ‰ ì‹¤íŒ¨({query}): {e}")
        return {}
    except Exception as e:
         print(f"âŒ (ëª©ë¡ ìƒì„±) Tavily ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜({query}): {e}")
         return {}

def extract_candidate_names(*texts: str) -> Set[str]:
    """í…ìŠ¤íŠ¸ì—ì„œ ìŠ¤íƒ€íŠ¸ì—… ì´ë¦„ í›„ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜"""
    candidates: Set[str] = set()
    for text in texts:
        if not text: continue
        for match in NAME_PATTERN.findall(text):
            name = match.strip()
            # í•„í„°ë§ ì¡°ê±´
            if (len(name) < 3 or name.upper() in STOPWORDS or
                not any(c.islower() for c in name if c.isalpha()) or
                len(name.split()) > 3 or
                not re.match(r"^[A-Z]", name) or
                re.search(r'\d{4}', name)):
                continue
            candidates.add(name)
    return candidates

def ai_filter_startups(candidates: List[str]) -> List[str]:
    """GPTë¥¼ ì‚¬ìš©í•˜ì—¬ í›„ë³´ ëª©ë¡ì—ì„œ ì‹¤ì œ ê¸°ì—…ëª…ë§Œ í•„í„°ë§í•˜ëŠ” í•¨ìˆ˜"""
    if not candidates: return []
    prompt = f"""ë‹¤ìŒ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì‹¤ì œ 'AI ê¸°ë°˜ êµìœ¡(EdTech) ìŠ¤íƒ€íŠ¸ì—…' ë˜ëŠ” ê´€ë ¨ ê¸°ì—…ì˜ ì´ë¦„ë§Œ ì •í™•íˆ ì¶”ì¶œí•´ì£¼ì„¸ìš”. ë‰´ìŠ¤ ì œëª©ì˜ ì¼ë¶€, ì¼ë°˜ ëª…ì‚¬, ê¸°ìˆ  ìš©ì–´, ì¸ë¬¼/ë„ì‹œ ì´ë¦„, ë³´ê³ ì„œ ì œëª© ë“±ì€ ëª¨ë‘ ì œì™¸í•˜ê³  ì˜¤ì§ íšŒì‚¬ ì´ë¦„ë§Œ ë‚¨ê²¨ì•¼ í•©ë‹ˆë‹¤. ê²°ê³¼ëŠ” íšŒì‚¬ ì´ë¦„ë§Œ í•œ ì¤„ì— í•˜ë‚˜ì”© ë‚˜ì—´í•´ì£¼ì„¸ìš”. ì¤‘ë³µì€ ì œê±°í•´ì£¼ì„¸ìš”.
ë¦¬ìŠ¤íŠ¸: {', '.join(candidates)}"""
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini", messages=[{"role": "user", "content": prompt}], temperature=0
        )
        text = response.choices[0].message.content.strip()
        return sorted(list(set(line.strip() for line in text.splitlines() if line.strip() and len(line.strip()) > 1)))
    except Exception as e:
        print(f"âš ï¸ AI í•„í„° ì‹¤íŒ¨: {e}. ì›ë³¸ í›„ë³´ ë°˜í™˜.")
        return sorted(list(set(candidates)))

def get_startup_context_for_eval(startup_name: str, max_results: int = 7) -> str:
    """ìƒì„¸ í‰ê°€ë¥¼ ìœ„í•´ íŠ¹ì • ìŠ¤íƒ€íŠ¸ì—…ì˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ Tavilyì—ì„œ ê²€ìƒ‰í•˜ëŠ” í•¨ìˆ˜"""
    print(f"  ğŸ” '{startup_name}' ìƒì„¸ ì •ë³´ ê²€ìƒ‰ ì¤‘ (Tavily)...")
    headers = {"Authorization": f"Bearer {TAVILY_API_KEY}", "Content-Type": "application/json"}
    query = f"{startup_name} EdTech company overview funding technology business model market size competition recent news"
    payload = { "query": query, "max_results": max_results, "include_answer": True, "search_depth": "advanced" }
    try:
        res = requests.post(TAVILY_URL, json=payload, headers=headers, timeout=30)
        res.raise_for_status()
        data = res.json()
        context_parts = []
        if data.get("answer"): context_parts.append(f"Tavily ìš”ì•½:\n{data['answer']}")
        if data.get("results"):
            for i, result in enumerate(data["results"]):
                title = result.get("title", "N/A")
                content = result.get("content", "N/A")
                if content and len(content) > 50:
                    context_parts.append(f"\nì¶œì²˜ {i+1} ({title}):\n{content}")
        if not context_parts:
             print(f"  âš ï¸ '{startup_name}'ì— ëŒ€í•œ ìƒì„¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
             return "ê²€ìƒ‰ëœ ìƒì„¸ ì •ë³´ ì—†ìŒ."
        print(f"  âœ… '{startup_name}' ìƒì„¸ ì •ë³´ ê²€ìƒ‰ ì™„ë£Œ ({len(context_parts)}ê°œ ì¶œì²˜).")
        full_context = "\n".join(context_parts)
        return full_context[:15000] # í† í° ì œí•œ ê³ ë ¤
    except requests.exceptions.RequestException as e:
        print(f"  âŒ (ìƒì„¸ ê²€ìƒ‰) Tavily ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {e}")
        return f"Tavily ìƒì„¸ ê²€ìƒ‰ ì‹¤íŒ¨: {e}"
    except Exception as e:
        print(f"  âŒ (ìƒì„¸ ê²€ìƒ‰) Tavily ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return f"Tavily ìƒì„¸ ê²€ìƒ‰ ì‹¤íŒ¨: {e}"

def evaluate_startup_with_ai(startup_name: str, context: str, criteria: Dict[str, List[str]]) -> Optional[Dict]:
    """GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠ¤íƒ€íŠ¸ì—… ìƒì„¸ í‰ê°€ë¥¼ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜"""
    print(f"  ğŸ¤– '{startup_name}' ìƒì„¸ í‰ê°€ ì‹œì‘ (GPT-4o-mini)...")
    criteria_prompt_text = ""
    for category, questions in criteria.items():
        criteria_prompt_text += f"\n### {category.upper()} í‰ê°€ ê¸°ì¤€:\n" + "\n".join(f"- {q}" for q in questions)
    prompt = f"""
ë‹¹ì‹ ì€ ë§¤ìš° ê¼¼ê¼¼í•œ EdTech VC íˆ¬ì ì‹¬ì‚¬ì—­ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ìŠ¤íƒ€íŠ¸ì—… '{startup_name}'ì— ëŒ€í•œ ì •ë³´(Context)ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ í‰ê°€ ê¸°ì¤€ë“¤ì„ **ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤**í•˜ì—¬ ë¶„ì„í•´ì£¼ì„¸ìš”.

**Context:**
{context}
---
**í‰ê°€ ê¸°ì¤€:**
{criteria_prompt_text}
---
**ë¶„ì„ ìš”ì²­:**
ìœ„ Contextì™€ í‰ê°€ ê¸°ì¤€ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ, **ê° 6ê°€ì§€ ì¹´í…Œê³ ë¦¬(technology, learning_effectiveness, market, competition, growth_potential, risk)ë³„**ë¡œ ìŠ¤íƒ€íŠ¸ì—…ì´ ì–¼ë§ˆë‚˜ ìš°ìˆ˜í•œì§€ **ì¢…í•©ì ì¸ ë¶„ì„**ì„ 1-2 ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ê³ , **1ì ì—ì„œ 5ì  ì‚¬ì´ì˜ ì ìˆ˜**ë¥¼ ë§¤ê²¨ì£¼ì„¸ìš”. (5ì ì´ ê°€ì¥ ìš°ìˆ˜í•¨. ë‹¨, riskëŠ” ì ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡ ë¦¬ìŠ¤í¬ê°€ ë‚®ìŒì„ ì˜ë¯¸)

**ì¶œë ¥ í˜•ì‹ (ì˜¤ì§ JSON ê°ì²´ë§Œ ì¶œë ¥, ë‹¤ë¥¸ ì„¤ëª… ì ˆëŒ€ ê¸ˆì§€):**
{{
  "startup_name": "{startup_name}",
  "evaluation_summary": {{
    "technology": {{ "analysis": "...", "score": ì ìˆ˜(1-5) }},
    "learning_effectiveness": {{ "analysis": "...", "score": ì ìˆ˜(1-5) }},
    "market": {{ "analysis": "...", "score": ì ìˆ˜(1-5) }},
    "competition": {{ "analysis": "...", "score": ì ìˆ˜(1-5) }},
    "growth_potential": {{ "analysis": "...", "score": ì ìˆ˜(1-5) }},
    "risk": {{ "analysis": "...", "score": ì ìˆ˜(1-5) }}
  }},
  "overall_assessment": "ì¢…í•© íˆ¬ì ì˜ê²¬..."
}}
"""
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini", messages=[{"role": "user", "content": prompt}],
            temperature=0.1, response_format={"type": "json_object"}
        )
        result_json = response.choices[0].message.content
        print(f"  âœ… '{startup_name}' ìƒì„¸ í‰ê°€ ì™„ë£Œ.")
        try:
            parsed_result = json.loads(result_json)
            if "evaluation_summary" in parsed_result and "overall_assessment" in parsed_result:
                 # ì ìˆ˜ê°€ ìˆ«ìì¸ì§€ í™•ì¸ ë° ë³€í™˜ (LLMì´ ê°€ë” ë¬¸ìì—´ë¡œ ì¤„ ìˆ˜ ìˆìŒ)
                 for category_data in parsed_result.get("evaluation_summary", {}).values():
                     if isinstance(category_data.get("score"), str):
                         try:
                             category_data["score"] = int(category_data["score"])
                         except ValueError:
                              print(f"âš ï¸ '{startup_name}' {category_data} ì ìˆ˜ ë³€í™˜ ì˜¤ë¥˜ -> 0ì  ì²˜ë¦¬")
                              category_data["score"] = 0
                     elif not isinstance(category_data.get("score"), (int, float)):
                         category_data["score"] = 0 # ìˆ«ìê°€ ì•„ë‹ˆë©´ 0ì  ì²˜ë¦¬

                 return parsed_result
            else:
                 print(f"  âŒ AI í‰ê°€ JSON êµ¬ì¡° ì˜¤ë¥˜. ì›ë³¸ ì‘ë‹µ:\n{result_json}")
                 return None
        except json.JSONDecodeError as e:
            print(f"  âŒ AI í‰ê°€ JSON íŒŒì‹± ì‹¤íŒ¨: {e}. ì›ë³¸ ì‘ë‹µ:\n{result_json}")
            return None
    except Exception as e:
        print(f"  âŒ AI í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# === â‘¤ LangGraph ë…¸ë“œ í•¨ìˆ˜ ì •ì˜ ===

def node_agent_a_generate_list(state: AgentState) -> Dict:
    """Agent A: ì´ˆê¸° ìŠ¤íƒ€íŠ¸ì—… ëª©ë¡ ìƒì„± ë° CSV ì €ì¥"""
    print("\n[bold blue]=== ğŸš€ 1ë‹¨ê³„: AI EdTech ìŠ¤íƒ€íŠ¸ì—… ëª©ë¡ ìƒì„± ì‹œì‘ ===[/]")
    all_candidates: Set[str] = set()
    for q in AGGREGATION_QUERIES:
        print(f"  ğŸ” Searching: {q}")
        data = tavily_search_for_aggregation(q)
        if not data: continue
        all_candidates.update(extract_candidate_names(data.get("answer", "")))
        for r in data.get("results", []):
            all_candidates.update(extract_candidate_names(r.get("title", ""), r.get("content", "")))

    print(f"  ğŸ§© 1ì°¨ ì¶”ì¶œëœ í›„ë³´ ìˆ˜: {len(all_candidates)}")
    if not all_candidates:
         print("  âŒ 1ì°¨ ì¶”ì¶œëœ í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
         return {"initial_candidates": []}

    print("  ğŸ¤– AI í•„í„°ë§ ì§„í–‰ ì¤‘...")
    filtered_startups = ai_filter_startups(sorted(list(all_candidates)))

    if filtered_startups:
        df = pd.DataFrame(filtered_startups, columns=["startup_name"])
        df.to_csv(INITIAL_STARTUP_CSV, index=False, encoding="utf-8-sig")
        print(f"  âœ… ìµœì¢… {len(filtered_startups)}ê°œ ìŠ¤íƒ€íŠ¸ì—… ì €ì¥ ì™„ë£Œ â†’ {INITIAL_STARTUP_CSV}")
        print("  --- ì´ˆê¸° ëª©ë¡ ---")
        for s in filtered_startups: print(f"  - {s}")
        print("  -----------------")
        return {"initial_candidates": filtered_startups}
    else:
        print(f"  âŒ AI í•„í„°ë§ í›„ ë‚¨ì€ ìŠ¤íƒ€íŠ¸ì—…ì´ ì—†ìŠµë‹ˆë‹¤.")
        pd.DataFrame(columns=["startup_name"]).to_csv(INITIAL_STARTUP_CSV, index=False, encoding="utf-8-sig")
        return {"initial_candidates": []}

def node_evaluate_all_and_rank(state: AgentState) -> Dict:
    """EvaluateAll & Rank: ì „ì²´ í‰ê°€, ìˆœìœ„ ë§¤ê¸°ê¸°, CSV ì €ì¥"""
    print("\n[bold blue]=== âœ¨ 2ë‹¨ê³„: ì „ì²´ ìŠ¤íƒ€íŠ¸ì—… ìƒì„¸ í‰ê°€ ë° ìˆœìœ„ ë§¤ê¸°ê¸° ===[/]")
    startup_list = state.get("initial_candidates", [])
    all_evaluations: List[Dict] = []

    if not startup_list:
        print("  âŒ í‰ê°€í•  ìŠ¤íƒ€íŠ¸ì—… ëª©ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
        return {"ranked_evaluations": [], "current_rank_index": 0}

    print(f"  â¡ï¸ ì´ {len(startup_list)}ê°œ ìŠ¤íƒ€íŠ¸ì—… í‰ê°€ ì‹œì‘...")
    for i, startup_name in enumerate(startup_list):
        print(f"\n  â­ ({i+1}/{len(startup_list)}) í‰ê°€ ëŒ€ìƒ: {startup_name}")
        startup_context = get_startup_context_for_eval(startup_name)
        evaluation_result = None
        if "ì‹¤íŒ¨" in startup_context or "ì—†ìŒ" in startup_context:
            print("    âŒ ì»¨í…ìŠ¤íŠ¸ ë¶€ì¡±/ì˜¤ë¥˜ë¡œ í‰ê°€ ë¶ˆê°€")
            all_evaluations.append({"startup_name": startup_name, "error": "Context Retrieval Failed", "total_score": 0})
        else:
            evaluation_result = evaluate_startup_with_ai(startup_name, startup_context, EVALUATION_CRITERIA)
            if evaluation_result:
                total_score = sum(int(cat_data.get("score", 0)) for cat_data in evaluation_result.get("evaluation_summary", {}).values()) # intë¡œ ë³€í™˜ ë³´ì¥
                evaluation_result["total_score"] = total_score
                all_evaluations.append(evaluation_result)
                print(f"    [bold yellow]âœ¨ ì´ì : {total_score} / 30 âœ¨[/]")
            else:
                print("    âŒ í‰ê°€ ê²°ê³¼ ìƒì„± ì‹¤íŒ¨")
                all_evaluations.append({"startup_name": startup_name, "error": "Evaluation Failed", "total_score": 0})
        # time.sleep(0.5) # í•„ìš”ì‹œ ëŒ€ê¸°

    # ì´ì  ê¸°ì¤€ ì •ë ¬
    sorted_evaluations = sorted(all_evaluations, key=lambda x: x.get("total_score", 0), reverse=True)

    # CSV ì €ì¥
    try:
        df_data = []
        for item in sorted_evaluations:
            row = {"startup_name": item.get("startup_name"),
                   "total_score": item.get("total_score"),
                   "overall_assessment": item.get("overall_assessment"),
                   "error": item.get("error")}
            if item.get("evaluation_summary"):
                for category, details in item["evaluation_summary"].items():
                    row[f"{category}_analysis"] = details.get("analysis")
                    row[f"{category}_score"] = details.get("score")
            df_data.append(row)
        df_ranked = pd.DataFrame(df_data)
        df_ranked.to_csv(RANKED_CSV_FILE, index=False, encoding="utf-8-sig")
        print(f"\n  âœ… ì´ {len(df_ranked)}ê°œ ìŠ¤íƒ€íŠ¸ì—… í‰ê°€ ê²°ê³¼ ë° ìˆœìœ„ë¥¼ {RANKED_CSV_FILE}ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\n  âŒ í‰ê°€ ê²°ê³¼ë¥¼ CSV íŒŒì¼({RANKED_CSV_FILE})ë¡œ ì €ì¥í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    return {"ranked_evaluations": sorted_evaluations, "current_rank_index": 0}

def node_select_ranked_startup(state: AgentState) -> Dict:
    """Select Ranked Startup: ìˆœìœ„ ëª©ë¡ì—ì„œ ë‹¤ìŒ ìŠ¤íƒ€íŠ¸ì—… ì„ íƒ"""
    print("\n[bold blue]=== ğŸ¯ 3ë‹¨ê³„: ìˆœìœ„ ê¸°ë°˜ ìŠ¤íƒ€íŠ¸ì—… ì„ íƒ ===[/]")
    ranked_list = state.get("ranked_evaluations", [])
    current_index = state.get("current_rank_index", 0)

    while current_index < len(ranked_list):
        selected_startup_details = ranked_list[current_index]
        # í‰ê°€ ì˜¤ë¥˜ê°€ ìˆì—ˆê±°ë‚˜ ì ìˆ˜ê°€ 0 ì´í•˜ì¸ ìŠ¤íƒ€íŠ¸ì—…ì€ ê±´ë„ˆë›°ê¸°
        if selected_startup_details.get("error") or selected_startup_details.get("total_score", 0) <= 0:
             print(f"  âš ï¸ {current_index + 1}ìˆœìœ„ '{selected_startup_details.get('startup_name')}' ê±´ë„ˆë›°ê¸° (ì˜¤ë¥˜ ë˜ëŠ” 0ì ). ë‹¤ìŒ ìˆœìœ„ ì‹œë„...")
             current_index += 1 # ë‹¤ìŒ ì¸ë±ìŠ¤ë¡œ
        else:
            # ìœ íš¨í•œ í›„ë³´ë¥¼ ì°¾ìœ¼ë©´ ë°˜í™˜
            print(f"  âœ… {current_index + 1}ìˆœìœ„ ì„ íƒ: [bold green]{selected_startup_details.get('startup_name')}[/] (ì´ì : {selected_startup_details.get('total_score')})")
            return {
                "current_startup_details": selected_startup_details,
                "current_rank_index": current_index + 1 # ë‹¤ìŒ ì„ íƒì„ ìœ„í•´ ì¸ë±ìŠ¤ ì¦ê°€
            }

    # ë£¨í”„ë¥¼ ë‹¤ ëŒì•˜ëŠ”ë° ìœ íš¨í•œ í›„ë³´ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ
    print("  âŒ ë” ì´ìƒ ì„ íƒí•  ìœ íš¨í•œ í›„ë³´ ìˆœìœ„ê°€ ì—†ìŠµë‹ˆë‹¤.")
    return {"current_startup_details": None, "current_rank_index": current_index} # None ë°˜í™˜


# --- Agents B-H (ê²€ì¦ ë¡œì§) ---
PROMPT_VALIDATE = ChatPromptTemplate.from_template(
    """System: ë‹¹ì‹ ì€ VC íˆ¬ì ì‹¬ì‚¬ì—­ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ìŠ¤íƒ€íŠ¸ì—… ì •ë³´ì™€ í‰ê°€ ìš”ì•½ì„ ë³´ê³ , '{criteria_check}' ê¸°ì¤€ì„ ì¶©ì¡±í•˜ëŠ”ì§€ **ê°„ë‹¨íˆ 'pass' ë˜ëŠ” 'fail'**ë¡œë§Œ íŒë‹¨í•´ì£¼ì„¸ìš”. ì¶”ê°€ ì„¤ëª… ì—†ì´ ì˜¤ì§ 'pass' ë˜ëŠ” 'fail' ë‹¨ì–´ë§Œ ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤.

Human: ìŠ¤íƒ€íŠ¸ì—… ì´ë¦„: {startup_name}
ì¢…í•© í‰ê°€ ì ìˆ˜: {total_score} / 30
ì¢…í•© ì˜ê²¬: {overall_assessment}

ê²€ì¦ ê¸°ì¤€: {criteria_check}

íŒë‹¨ ('pass' ë˜ëŠ” 'fail'):"""
)

def run_validation_agent(startup_details: Dict, criteria_check: str, agent_name: str) -> Literal["continue", "reject"]:
    """B-H ê²€ì¦ ì—ì´ì „íŠ¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print(f"--- ğŸ‘¤ Agent {agent_name}: ê²€ì¦ ì‹œì‘ ---")
    if not startup_details:
        print(f"  âŒ ê²€ì¦í•  ìŠ¤íƒ€íŠ¸ì—… ì •ë³´ ì—†ìŒ -> REJECT")
        return "reject"

    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0, openai_api_key=OPENAI_API_KEY)
    prompt = PROMPT_VALIDATE.format_messages(
        startup_name=startup_details.get("startup_name", "N/A"),
        total_score=startup_details.get("total_score", "N/A"),
        overall_assessment=startup_details.get("overall_assessment", "N/A"),
        criteria_check=criteria_check
    )

    try:
        # LLM í˜¸ì¶œ ì‹œë„ (ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ë“± ëŒ€ë¹„)
        for _ in range(3): # ìµœëŒ€ 3ë²ˆ ì¬ì‹œë„
            try:
                response = llm.invoke(prompt).content.strip().lower()
                if response in ["pass", "fail"]:
                    decision = "continue" if response == "pass" else "reject"
                    print(f"  â†³ ê²€ì¦ ê²°ê³¼: {decision.upper()}")
                    return decision
                else:
                    print(f"  âš ï¸ Agent {agent_name} ì˜ˆìƒì¹˜ ëª»í•œ ì‘ë‹µ: '{response}' -> REJECT ì²˜ë¦¬")
                    return "reject"
            except Exception as retry_e:
                print(f"  âš ï¸ Agent {agent_name} LLM í˜¸ì¶œ ì¬ì‹œë„ ì¤‘... ì˜¤ë¥˜: {retry_e}")
                time.sleep(1) # ì ì‹œ ëŒ€ê¸° í›„ ì¬ì‹œë„
        # ì¬ì‹œë„ ëª¨ë‘ ì‹¤íŒ¨
        print(f"  âŒ Agent {agent_name} LLM í˜¸ì¶œ ìµœì¢… ì‹¤íŒ¨ -> REJECT ì²˜ë¦¬")
        return "reject"
    except Exception as e:
        print(f"  âŒ Agent {agent_name} ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e} -> REJECT ì²˜ë¦¬")
        return "reject"

def node_agent_b_validate(state: AgentState) -> Dict:
    decision = run_validation_agent(state.get("current_startup_details"),
                                     "ì´ˆê¸° 'ê³ ìœ„í—˜-ê³ ì„±ì¥' í”„ë¡œí•„ (ëª©ì , ì†ë„, ì•„ì´ë””ì–´, ë¶ˆí™•ì‹¤ì„±, ìê¸ˆ, ëª©í‘œ)ì— ë¶€í•©í•˜ëŠ”ê°€?", "B")
    return {"last_decision": decision}

def node_agent_c_validate(state: AgentState) -> Dict:
    decision = run_validation_agent(state.get("current_startup_details"),
                                     "ê¸°ìˆ ì  í˜ì‹ ì„±ì´ë‚˜ ê²½ìŸ ìš°ìœ„ê°€ ì¶©ë¶„íˆ ì…ì¦ë˜ì—ˆëŠ”ê°€?", "C")
    return {"last_decision": decision}

def node_agent_d_validate(state: AgentState) -> Dict:
    decision = run_validation_agent(state.get("current_startup_details"),
                                     "ì‹¤ì œ í•™ìŠµ íš¨ê³¼ë‚˜ ì‚¬ìš©ì ë§Œì¡±ë„ ê·¼ê±°ê°€ ì œì‹œë˜ì—ˆëŠ”ê°€?", "D")
    return {"last_decision": decision}

def node_agent_e_validate(state: AgentState) -> Dict:
    decision = run_validation_agent(state.get("current_startup_details"),
                                     "ì‹œì¥ ê·œëª¨, ìˆ˜ìµ ëª¨ë¸, ê³ ê° í™•ë³´ ì¸¡ë©´ì—ì„œ ë§¤ë ¥ì ì¸ê°€?", "E")
    return {"last_decision": decision}

def node_agent_f_validate(state: AgentState) -> Dict:
    decision = run_validation_agent(state.get("current_startup_details"),
                                     "ê²½ìŸì‚¬ ëŒ€ë¹„ ì°¨ë³„ì ì´ë‚˜ ì§„ì… ì¥ë²½ì´ ëª…í™•í•œê°€?", "F")
    return {"last_decision": decision}

def node_agent_g_validate(state: AgentState) -> Dict:
    decision = run_validation_agent(state.get("current_startup_details"),
                                     "ì‹œì¥ í™•ì¥, ê¸€ë¡œë²Œ ì§„ì¶œ ë“± 10ë°° ì´ìƒ ì„±ì¥ ì ì¬ë ¥ì´ ë³´ì´ëŠ”ê°€?", "G")
    return {"last_decision": decision}

def node_agent_h_validate(state: AgentState) -> Dict:
    decision = run_validation_agent(state.get("current_startup_details"),
                                     "ì¬ë¬´, ë²•ë¥ , ê¸°ìˆ , ì‹œì¥ ë“± ì£¼ìš” ë¦¬ìŠ¤í¬ê°€ ê´€ë¦¬ ê°€ëŠ¥í•œ ìˆ˜ì¤€ì¸ê°€?", "H")
    return {"last_decision": decision}

def node_report_success(state: AgentState) -> Dict:
    """ìµœì¢… í†µê³¼ ë³´ê³  ë…¸ë“œ"""
    print("\n" + "="*60)
    print(f"[bold green]ğŸ‰ ìµœì¢… ê²€ì¦ í†µê³¼ ğŸ‰[/]")
    startup = state.get('current_startup_details', {})
    rank = state.get('current_rank_index', 0) # í˜„ì¬ ì¸ë±ìŠ¤ëŠ” ë‹¤ìŒ ëŒ€ìƒì´ë¯€ë¡œ -1 í•˜ë©´ ì•ˆë¨
    print(f"  ğŸ… ìˆœìœ„: {rank}")
    print(f"  â­ ìŠ¤íƒ€íŠ¸ì—…: {startup.get('startup_name', 'ì •ë³´ ì—†ìŒ')}")
    print(f"  âœ¨ ì´ì : {startup.get('total_score', 'N/A')} / 30")
    print(f"  ğŸ“ ì¢…í•© ì˜ê²¬: {startup.get('overall_assessment', 'N/A')}")
    if startup.get("evaluation_summary"):
        print("\n  --- ìƒì„¸ ì ìˆ˜ ---")
        for cat, details in startup["evaluation_summary"].items():
             print(f"    - {cat.capitalize()}: {details.get('score', 'N/A')}/5")
    print("="*60 + "\n")
    return {}

# === â‘¥ LangGraph ê·¸ë˜í”„ êµ¬ì„± ===
def build_graph():
    graph = StateGraph(AgentState)

    # ë…¸ë“œ ì¶”ê°€
    graph.add_node("Agent_A_Generate_List", node_agent_a_generate_list)
    graph.add_node("Evaluate_All_And_Rank", node_evaluate_all_and_rank)
    graph.add_node("Select_Ranked_Startup", node_select_ranked_startup)
    graph.add_node("Agent_B_Validate", node_agent_b_validate)
    graph.add_node("Agent_C_Validate", node_agent_c_validate)
    graph.add_node("Agent_D_Validate", node_agent_d_validate)
    graph.add_node("Agent_E_Validate", node_agent_e_validate)
    graph.add_node("Agent_F_Validate", node_agent_f_validate)
    graph.add_node("Agent_G_Validate", node_agent_g_validate)
    graph.add_node("Agent_H_Validate", node_agent_h_validate)
    graph.add_node("Report_Success", node_report_success)

    # ì§„ì…ì  ì„¤ì •
    graph.set_entry_point("Agent_A_Generate_List")

    # ì—£ì§€ ë° ë¼ìš°í„° ì •ì˜
    def router_after_a(state: AgentState):
        return "evaluate_all" if state.get("initial_candidates") else END
    graph.add_conditional_edges("Agent_A_Generate_List", router_after_a, {
        "evaluate_all": "Evaluate_All_And_Rank", END: END
    })

    def router_after_evaluate(state: AgentState):
         return "select_ranked" if state.get("ranked_evaluations") else END
    graph.add_conditional_edges("Evaluate_All_And_Rank", router_after_evaluate, {
        "select_ranked": "Select_Ranked_Startup", END: END
    })

    def router_after_select(state: AgentState):
        # node_select_ranked_startup ì—ì„œ ìœ íš¨í•˜ì§€ ì•Šì€ í›„ë³´ëŠ” ê±´ë„ˆë›°ê³  Noneì„ ë°˜í™˜í•¨
        return "validate_b" if state.get("current_startup_details") else END
    graph.add_conditional_edges("Select_Ranked_Startup", router_after_select, {
        "validate_b": "Agent_B_Validate", END: END # Noneì´ë©´ ì¢…ë£Œ
    })

    # B-H ê²€ì¦ ë¼ìš°í„°
    def router_after_validation(state: AgentState):
        return "proceed" if state.get("last_decision") == "continue" else "reject_and_select_new"

    graph.add_conditional_edges("Agent_B_Validate", router_after_validation, {
        "proceed": "Agent_C_Validate", "reject_and_select_new": "Select_Ranked_Startup" # ì‹¤íŒ¨ ì‹œ ë‹¤ìŒ ìˆœìœ„ ì„ íƒ
    })
    graph.add_conditional_edges("Agent_C_Validate", router_after_validation, {
        "proceed": "Agent_D_Validate", "reject_and_select_new": "Select_Ranked_Startup"
    })
    graph.add_conditional_edges("Agent_D_Validate", router_after_validation, {
        "proceed": "Agent_E_Validate", "reject_and_select_new": "Select_Ranked_Startup"
    })
    graph.add_conditional_edges("Agent_E_Validate", router_after_validation, {
        "proceed": "Agent_F_Validate", "reject_and_select_new": "Select_Ranked_Startup"
    })
    graph.add_conditional_edges("Agent_F_Validate", router_after_validation, {
        "proceed": "Agent_G_Validate", "reject_and_select_new": "Select_Ranked_Startup"
    })
    graph.add_conditional_edges("Agent_G_Validate", router_after_validation, {
        "proceed": "Agent_H_Validate", "reject_and_select_new": "Select_Ranked_Startup"
    })
    graph.add_conditional_edges("Agent_H_Validate", router_after_validation, {
        "proceed": "Report_Success", # ìµœì¢… í†µê³¼
        "reject_and_select_new": "Select_Ranked_Startup" # ì‹¤íŒ¨ ì‹œ ë‹¤ìŒ ìˆœìœ„ ì‹œë„
    })

    # ì¢…ë£Œ ì—£ì§€
    graph.add_edge("Report_Success", END)

    # ì»´íŒŒì¼
    return graph.compile()

# === â‘¦ ë©”ì¸ ì‹¤í–‰ ë¡œì§ ===
if __name__ == "__main__":
    app = build_graph()
    init_state: Dict = {}

    print("ğŸš€ [bold]EdTech íˆ¬ì íŒŒì´í”„ë¼ì¸ (A -> í‰ê°€/ë­í‚¹ -> ìˆœìœ„ ê¸°ë°˜ B-H ê²€ì¦) ì‹¤í–‰ ì‹œì‘[/]")

    try:
        # configì— recursion_limit ì„¤ì • (ë‹¨ê³„ê°€ ë§ìœ¼ë¯€ë¡œ ë„‰ë„‰í•˜ê²Œ ì„¤ì •)
        final_state = app.invoke(init_state, config={"recursion_limit": 200}) # ì˜ˆ: ìµœëŒ€ 200ë‹¨ê³„

        print("\n=== ê·¸ë˜í”„ ì‹¤í–‰ ì¢…ë£Œ ===")

        # ìµœì¢… ìƒíƒœ í™•ì¸ (Report_Success ë…¸ë“œê°€ ì‹¤í–‰ë˜ì—ˆëŠ”ì§€ ì—¬ë¶€ íŒë‹¨)
        # ë§ˆì§€ë§‰ ë…¸ë“œê°€ Report_Success ì´ê±°ë‚˜, last_decisionì´ continue ì´ê³  current_startup_detailsê°€ ìˆìœ¼ë©´ ì„±ê³µ
        # (ë” ì •í™•í•œ ë°©ë²•ì€ LangSmith ì¶”ì ì„ ë³´ê±°ë‚˜ Report_Success ë…¸ë“œì—ì„œ íŠ¹ì • flag ìƒíƒœ ì¶”ê°€)
        if final_state.get("last_decision") == "continue" and final_state.get("current_startup_details"):
             # ì„±ê³µ ë©”ì‹œì§€ëŠ” Report_Success ë…¸ë“œì—ì„œ ì´ë¯¸ ì¶œë ¥ë¨
             pass
        else:
            print("[bold red]âŒ ìµœì¢… ê²€ì¦ì„ í†µê³¼í•œ ìŠ¤íƒ€íŠ¸ì—…ì´ ì—†ìŠµë‹ˆë‹¤.[/]")


    except Exception as e:
        print(f"\nâŒ ê·¸ë˜í”„ ì‹¤í–‰ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}")
        traceback.print_exc()

    print("\n[bold magenta]=== ğŸ‰ íŒŒì´í”„ë¼ì¸ ìµœì¢… ì™„ë£Œ ===[/]")